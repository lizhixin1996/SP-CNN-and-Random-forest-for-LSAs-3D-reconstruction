{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-5b7975c5f385>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmnist\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtyping\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_typing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtools\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmodule_util\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_module_util\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlazy_loader\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLazyLoader\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_LazyLoader\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;31m# Bring in subpackages.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdistribute\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;31m# from tensorflow.python import keras\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\data\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;31m# pylint: disable=unused-import\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mexperimental\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset_ops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mAUTOTUNE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset_ops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\data\\experimental\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrouping\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mgroup_by_window\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrouping\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mReducer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 116\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minterleave_ops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mchoose_from_datasets\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    117\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minterleave_ops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mparallel_interleave\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minterleave_ops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msample_from_datasets\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_find_spec\u001b[1;34m(name, path, target)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\importlib\\_bootstrap_external.py\u001b[0m in \u001b[0;36mfind_spec\u001b[1;34m(cls, fullname, path, target)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\importlib\\_bootstrap_external.py\u001b[0m in \u001b[0;36m_get_spec\u001b[1;34m(cls, fullname, path, target)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\importlib\\_bootstrap_external.py\u001b[0m in \u001b[0;36mfind_spec\u001b[1;34m(self, fullname, target)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\importlib\\_bootstrap_external.py\u001b[0m in \u001b[0;36m_path_stat\u001b[1;34m(path)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import nibabel as nib\n",
    "#import pandas as pd\n",
    "import os,sys\n",
    "import math\n",
    "import os.path\n",
    "import cv2\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pydicom\n",
    "from PIL import Image\n",
    "import cv2 as cv\n",
    "import random\n",
    "import pickle\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import Conv3D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.python.keras.utils import np_utils\n",
    "from tensorflow.keras.models import load_model\n",
    "from skimage.transform import resize\n",
    "from skimage import io, transform\n",
    "#from numba import jit\n",
    "import copy\n",
    "from scipy import ndimage as ndi\n",
    "from scipy import absolute\n",
    "from itertools import combinations_with_replacement\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#sys.path.append(r\"C:\\Users\\DELL\\anaconda3\\Lib\\site-packages\\pcost\")\n",
    "import pcost\n",
    "from pcost.p_cost import Cost\n",
    "from pcost import MPP_BT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d3_plat_1 = [[0,0,0],[-1,-1,0],[0,-1,0],[1,-1,0],[1,0,0],[1,1,0],[0,1,0],[-1,1,0],[-1,0,0],\n",
    "             [0,0,1],[-1,-1,1],[0,-1,1],[1,-1,1],[1,0,1],[1,1,1],[0,1,1],[-1,1,1],[-1,0,1],\n",
    "             [0,0,-1],[-1,-1,-1],[0,-1,-1],[1,-1,-1],[1,0,-1],[1,1,-1],[0,1,-1],[-1,1,-1],[-1,0,-1]]\n",
    "d2_plat_1 = [[0,0,0],[-1,-1,0],[0,-1,0],[1,-1,0],[1,0,0],[1,1,0],[0,1,0],[-1,1,0],[-1,0,0]]\n",
    "d3_plat_1_5 = [[0,0,0],[-5,-5,0],[0,-5,0],[5,-5,0],[5,0,0],[5,5,0],[0,5,0],[-5,5,0],[-5,0,0],\n",
    "               [0,0,5],[-5,-5,5],[0,-5,5],[5,-5,5],[5,0,5],[5,5,5],[0,5,5],[-5,5,5],[-5,0,5],\n",
    "               [0,0,-5],[-5,-5,-5],[0,-5,-5],[5,-5,-5],[5,0,-5],[5,5,-5],[0,5,-5],[-5,5,-5],[-5,0,-5]]\n",
    "d3_plat_1_no0 = [[0,0,-1],[-1,-1,-1],[0,-1,-1],[1,-1,-1],[1,0,-1],[1,1,-1],[0,1,-1],[-1,1,-1],[-1,0,-1],\n",
    "                 [-1,-1,0],[0,-1,0],[1,-1,0],[1,0,0],[1,1,0],[0,1,0],[-1,1,0],[-1,0,0],\n",
    "             [0,0,1],[-1,-1,1],[0,-1,1],[1,-1,1],[1,0,1],[1,1,1],[0,1,1],[-1,1,1],[-1,0,1]]\n",
    "d3_plat_8 = [[0,0,0],[1,0,0],[1,1,0],[0,1,0],\n",
    "             [0,0,1],[1,0,1],[1,1,1],[0,1,1]]\n",
    "d3_plat_8_no0 = [[1,0,0],[1,1,0],[0,1,0],\n",
    "             [0,0,1],[1,0,1],[1,1,1],[0,1,1]]\n",
    "patch0 = 25\n",
    "patch1 = 25\n",
    "patch2 = 25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "path = r'E:\\article3\\样例文件\\Branches\\20190112_S27_S65'\n",
    "files = os.listdir(path)\n",
    "\n",
    "slices = []\n",
    "m = 0\n",
    "for i in files:\n",
    "    m=m+1\n",
    "    if m>128:\n",
    "        break\n",
    "    else:\n",
    "        img = pydicom.dcmread(os.path.join(path,i))\n",
    "        data = img.pixel_array\n",
    "        #slices.append(img)\n",
    "        #print(data[0][1])\n",
    "        #data = data.reshape(768,196)\n",
    "        #data = data.T\n",
    "        a = data.tolist()\n",
    "        #a = np.array(a)\n",
    "        #print(a.shape)\n",
    "        slices.append(a)\n",
    "slices = np.array(slices)\n",
    "\n",
    "target_3d = np.array(slices)\n",
    "target_3d = target_3d.T\n",
    "chang = target_3d.shape[0]\n",
    "kuan = target_3d.shape[1]\n",
    "gao = target_3d.shape[2]\n",
    "target_3d_2 = np.zeros((chang,kuan,gao))\n",
    "target_3d_2.tolist\n",
    "\n",
    "for x in range(chang):\n",
    "    for y in range(kuan):\n",
    "        for z in range(gao):\n",
    "            target_3d_2[x,y,z] = target_3d[chang-x-1,kuan-y-1,z]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "windows = 0\n",
    "patient_name = \n",
    "file_path = \n",
    "file_number = \n",
    "model_path = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "conda activate tensorflow2 && cd /home/zxli/article3/HT && runipy seg_CAO_HONG_XIA.ipynb "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#usually default, if not neccessary, do not need change\n",
    "intsh = 120\n",
    "intsl = 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(path):#定义一个“读取图像”函数，用来读取图像\n",
    "    image_data = nib.load(path)\n",
    "    return image_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_3 = file_path+file_number+file_number+'_n4.nii'\n",
    "target_3 = read_data(path_3)#使用“读取图像”函数\n",
    "\n",
    "target_3d_3 = target_3.get_fdata()\n",
    "target_3d_3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_3d_normalization = (target_3d_3/1)*1\n",
    "#target_same2 = target_3d_normalization[125:475, 375:505, 0:128]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target_same = target_3d_normalization[110:470, 370:550, 5:123]\n",
    "# target_3d_mask = target_3d_normalization[105:475, 365:555, 0:128]\n",
    "#target_same = target_3d_normalization[5:345, 5:125, 5:123]\n",
    "target_3d_mask = target_3d_normalization#[115:485, 395:545, 0:128]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_3d_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \n",
    "patient_files = os.listdir(path)\n",
    "m = 0\n",
    "for file in patient_files:\n",
    "    m += 1\n",
    "    #print(file)\n",
    "    #file_path = os.path.join(path,file)\n",
    "    if r'HEAD' in file:\n",
    "        dcm_files_path = os.path.join(path,file)\n",
    "        dcm_files = os.listdir(dcm_files_path)\n",
    "\n",
    "        for dcm_file in dcm_files:\n",
    "            print(dcm_file)\n",
    "            if r'TOF' in dcm_file and r'MIP' not in dcm_file:\n",
    "                dcm_file_path = os.path.join(dcm_files_path,dcm_file)\n",
    "                #print('dfp',dcm_file_path)\n",
    "                tof_files = os.listdir(dcm_file_path)\n",
    "                #print(tof_files[0])\n",
    "                    #print(i)\n",
    "        #     if m==30:\n",
    "                dcm_path = os.path.join(dcm_file_path,tof_files[0])\n",
    "                print(dcm_path)\n",
    "                img = pydicom.dcmread(dcm_path)\n",
    "                #print(img)\n",
    "                print(img.PixelSpacing[0])\n",
    "                print(img.SpacingBetweenSlices)\n",
    "                #print(500 in img.AcquisitionMatrix and 462 in img.AcquisitionMatrix and 0 in img.AcquisitionMatrix)\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "origin0 = img.PixelSpacing[0]\n",
    "origin1 = img.PixelSpacing[1]\n",
    "origin2 = img.SpacingBetweenSlices  \n",
    "\n",
    "insert0 = origin0/0.13\n",
    "insert1 = origin1/0.13\n",
    "insert2 = origin2/0.13\n",
    "\n",
    "def bilinear(org_img, org_shape, dst_shape):\n",
    "    dst_img = np.zeros((dst_shape[0], dst_shape[1], dst_shape[2]))\n",
    "    dst_h, dst_w, dst_d = dst_shape\n",
    "    org_h, org_w, org_d = org_shape\n",
    "    for i in range(dst_h):\n",
    "        print(i)\n",
    "        for j in range(dst_w):\n",
    "            for k in range(dst_d):\n",
    "                src_x = i * float(org_h / dst_h)\n",
    "                src_y = j * float(org_w / dst_w)\n",
    "                src_z = k * float(org_d / dst_d)\n",
    "                src_x_int = i * org_h // dst_h\n",
    "                src_y_int = j * org_w // dst_w\n",
    "                src_z_int = k * org_d // dst_d\n",
    "                a = src_x - src_x_int\n",
    "                b = src_y - src_y_int\n",
    "                c = src_z - src_z_int\n",
    "\n",
    "                if src_x_int+1 == org_h or src_y_int+1 == org_w or src_z_int+1 == org_d:\n",
    "                    dst_img[i, j, k] = org_img[src_x_int, src_y_int, src_z_int]\n",
    "                    continue\n",
    "                # print(src_x_int, src_y_int)\n",
    "                dst_img[i, j, k] = (1. - a) * (1. - b) * (1. - c) * org_img[src_x_int+1, src_y_int+1, src_z_int] + \\\n",
    "                                   (1. - a) * b * (1. - c) * org_img[src_x_int, src_y_int+1, src_z_int] + \\\n",
    "                                    a * (1. - b) * (1. - c) * org_img[src_x_int+1, src_y_int, src_z_int] + \\\n",
    "                                    a * b * (1. - c) * org_img[src_x_int, src_y_int, src_z_int] + \\\n",
    "                                    (1. - a) * (1. - b) * c * org_img[src_x_int+1, src_y_int+1, src_z_int+1] + \\\n",
    "                                   (1. - a) * b * c * org_img[src_x_int, src_y_int+1, src_z_int+1] + \\\n",
    "                                    a * (1. - b) * c * org_img[src_x_int+1, src_y_int, src_z_int+1] + \\\n",
    "                                    a * b * c * org_img[src_x_int, src_y_int, src_z_int+1]\n",
    "    \n",
    "    return dst_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    img = target_3d_3\n",
    "    img_shape = (img.shape[0], img.shape[1], img.shape[2])\n",
    "    dst_shape = (round(insert0*img_shape[0]), round(insert1*img_shape[1]), round(insert2*img_shape[2]))\n",
    "    target_3d_mask_insert = bilinear(img, img_shape, dst_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b,c = target_3d_mask_insert.shape\n",
    "target_same_insert = target_3d_mask_insert[12:a-12,12:b-12,12:c-12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "affine = np.diag([1, 2, 3,1]) \n",
    "img_3d = nib.Nifti1Image(target_same_insert, affine) \n",
    "img_3d.shape \n",
    "nib.save(img_3d, file_path+file_number+file_number+'_same1.nii')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b,c = target_same_insert.shape\n",
    "target_3d_look = np.zeros((a,b,c))\n",
    "for x in range(a):\n",
    "    for y in range(b):\n",
    "        for z in range(c):\n",
    "            if target_same_insert[x,y,z]>130:\n",
    "                target_3d_look[x,y,z] = 255\n",
    "            else:\n",
    "                target_3d_look[x,y,z] = 0\n",
    "affine = np.diag([1, 2, 3,1])\n",
    "img_3d = nib.Nifti1Image(target_3d_look, affine)\n",
    "img_3d.shape\n",
    "nib.save(img_3d, file_path+file_number+file_number+'_look.nii')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@jit(nopython=True)\n",
    "def predict1(origin,patchx,patchy,patchz,zsgive,zslgive):\n",
    "    aa,bb,cc = origin.shape\n",
    "    target = np.zeros((aa-(patchx-1),bb-(patchy-1),cc-(patchz-1)),dtype=int)\n",
    "    a,b,c = target.shape\n",
    "    print(a,b,c)\n",
    "    \n",
    "    #model_artifact = load_model(r'E:\\article3\\样例文件\\Branches\\S57\\micro_artifact1.h5')\n",
    "    #model_micro = load_model(r'E:\\article3\\样例文件\\Branches\\S57\\micro_vessel.h5')\n",
    "    model_complex = load_model(model_path)\n",
    "\n",
    "    #gc.disable()\n",
    "    semble = []\n",
    "    for x in range(1,a-1,2):\n",
    "        #print(x)\n",
    "        for y in range(1,b-1,2):\n",
    "            for z in range(5,int(c/2)+0,2):\n",
    "                semble.append([x,y,z])\n",
    "    print(len(semble))\n",
    "    for n in range(len(semble)):\n",
    "        if n%10000 == 0:\n",
    "            print(n/10000)\n",
    "        x,y,z = semble[n]\n",
    "        if (x<int(a/10) or x>a-int(a/10)):\n",
    "            zs = zsgive+40\n",
    "            zsl = zslgive+40\n",
    "        else:\n",
    "            zs = zsgive\n",
    "            zsl = zslgive\n",
    "        #if (100>x or x>a-100) and z<search_z:\n",
    "        #zs = 150\n",
    "        #zsl = 125\n",
    "        #zs = 120\n",
    "        #zsl = 100\n",
    "#         elif 100<=x<=a-100 and z<search_z:\n",
    "#             zs = 55\n",
    "#             zsl = 40\n",
    "#         elif 70<=x<=a-160 and z>=search_z:\n",
    "#             zs = 50\n",
    "#             zsl = 35\n",
    "#         else:\n",
    "#             zs = 65\n",
    "#             zsl = 55\n",
    "        if origin[int(x+(patchx-1)/2),int(y+(patchy-1)/2),int(z+(patchz-1)/2)] <= zsl:\n",
    "            target[x,y,z] = 0\n",
    "            #pass\n",
    "        elif origin[int(x+(patchx-1)/2),int(y+(patchy-1)/2),int(z+(patchz-1)/2)] >= zs:# and z<=50:\n",
    "            target[x,y,z] = 255\n",
    "            for i,j,k in d3_plat_8:\n",
    "                if origin[int(x+(patchx-1)/2)+i,int(y+(patchy-1)/2)+j,int(z+(patchz-1)/2)+k]>zsl:\n",
    "                    target[x+i,y+j,z+k] = 255\n",
    "#         elif origin[int(x+(patchx-1)/2),int(y+(patchy-1)/2),int(z+(patchz-1)/2)] >= 65 and z>50:\n",
    "#             target[x,y,z] = 255\n",
    "        else:\n",
    "            \n",
    "            pre = []\n",
    "            region = np.array(origin[int(x):int(x+patchx),int(y):int(y+patchy),int(z):int(z+patchz)])\n",
    "            max_pre = region.max()\n",
    "            past = 255/max_pre\n",
    "            #past = 1\n",
    "            region = np.array(region)\n",
    "            region_complex = region*past\n",
    "            img_complex = resize(region_complex, output_shape=(1,patchz,patchy,patchx,1))\n",
    "            prediction_complex_m = model_complex(img_complex,training = False)\n",
    "            prediction_complex = np.array(prediction_complex_m)\n",
    "\n",
    "            if prediction_complex[0][1] >= 0.5:\n",
    "                target[x,y,z] = 255\n",
    "                for i,j,k in d3_plat_8_no0:\n",
    "                    if origin[int(x+(patchx-1)/2)+i,int(y+(patchy-1)/2)+j,int(z+(patchz-1)/2)+k]>zsl:\n",
    "                        target[x+i,y+j,z+k] = 255\n",
    "                    else:\n",
    "                        target[x+i,y+j,z+k] = 0\n",
    "            else:\n",
    "                target[x,y,z] = 0\n",
    "    return target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@jit(nopython=True)\n",
    "def predict2(origin,patchx,patchy,patchz,zsgive,zslgive):\n",
    "    aa,bb,cc = origin.shape\n",
    "    target = np.zeros((aa-(patchx-1),bb-(patchy-1),cc-(patchz-1)),dtype=int)\n",
    "    a,b,c = target.shape\n",
    "    print(a,b,c)\n",
    "    \n",
    "    #model_artifact = load_model(r'E:\\article3\\样例文件\\Branches\\S57\\micro_artifact1.h5')\n",
    "    #model_micro = load_model(r'E:\\article3\\样例文件\\Branches\\S57\\micro_vessel.h5')\n",
    "    model_complex = load_model(model_path)\n",
    "\n",
    "    #gc.disable()\n",
    "    semble = []\n",
    "    for x in range(1,a-1,2):\n",
    "        #print(x)\n",
    "        for y in range(1,b-1,2):\n",
    "            for z in range(int(c/2)+0,c-5,2):\n",
    "                semble.append([x,y,z])\n",
    "    print(len(semble))\n",
    "    for n in range(len(semble)):\n",
    "        if n%10000 == 0:\n",
    "            print(n/10000)\n",
    "        x,y,z = semble[n]\n",
    "        if (x<int(a/10) or x>a-int(a/10)):\n",
    "            zs = zsgive+40\n",
    "            zsl = zslgive+40\n",
    "        else:\n",
    "            zs = zsgive\n",
    "            zsl = zslgive\n",
    "        #if (100>x or x>a-100) and z<search_z:\n",
    "        #zs = 150\n",
    "        #zsl = 125\n",
    "        #zs = intsh\n",
    "        #zsl = intsl\n",
    "#         elif 100<=x<=a-100 and z<search_z:\n",
    "#             zs = 55\n",
    "#             zsl = 40\n",
    "#         elif 70<=x<=a-160 and z>=search_z:\n",
    "#             zs = 50\n",
    "#             zsl = 35\n",
    "#         else:\n",
    "#             zs = 65\n",
    "#             zsl = 55\n",
    "        if origin[int(x+(patchx-1)/2),int(y+(patchy-1)/2),int(z+(patchz-1)/2)] < zsl:\n",
    "            target[x,y,z] = 0\n",
    "            #pass\n",
    "        elif origin[int(x+(patchx-1)/2),int(y+(patchy-1)/2),int(z+(patchz-1)/2)] > zs:# and z<=50:\n",
    "            target[x,y,z] = 255\n",
    "            for i,j,k in d3_plat_8:\n",
    "                if origin[int(x+(patchx-1)/2)+i,int(y+(patchy-1)/2)+j,int(z+(patchz-1)/2)+k]>zsl:\n",
    "                    target[x+i,y+j,z+k] = 255\n",
    "#         elif origin[int(x+(patchx-1)/2),int(y+(patchy-1)/2),int(z+(patchz-1)/2)] >= 65 and z>50:\n",
    "#             target[x,y,z] = 255\n",
    "        else:\n",
    "            pre = []\n",
    "            region = np.array(origin[int(x):int(x+patchx),int(y):int(y+patchy),int(z):int(z+patchz)])\n",
    "            max_pre = region.max()\n",
    "            past = 255/max_pre\n",
    "            region = np.array(region)\n",
    "            region_complex = region*past\n",
    "            img_complex = resize(region_complex, output_shape=(1,patchz,patchy,patchx,1))\n",
    "            prediction_complex_m = model_complex(img_complex,training = False)\n",
    "            prediction_complex = np.array(prediction_complex_m)\n",
    "\n",
    "            if prediction_complex[0][1] >= 0.5:\n",
    "                target[x,y,z] = 255\n",
    "                for i,j,k in d3_plat_8_no0:\n",
    "                    if origin[int(x+(patchx-1)/2)+i,int(y+(patchy-1)/2)+j,int(z+(patchz-1)/2)+k]>zsl:\n",
    "                        target[x+i,y+j,z+k] = 255\n",
    "                    else:\n",
    "                        target[x+i,y+j,z+k] = 0\n",
    "            else:\n",
    "                target[x,y,z] = 0\n",
    "                        \n",
    "    return target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "target_3d_mask_predict1 = predict1(target_3d_mask_insert,patch0,patch1,patch2,intsh,intsl)\n",
    "end = time.time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "target_3d_mask_predict2 = predict2(target_3d_mask_insert,patch0,patch1,patch2,intsh,intsl)\n",
    "end = time.time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b,c = target_3d_mask_predict2.shape\n",
    "for x in range(a):\n",
    "    for y in range(b):\n",
    "        for z in range(c):\n",
    "            if target_3d_mask_predict2[x,y,z] == 255:\n",
    "                target_3d_mask_predict1[x,y,z] = 255\n",
    "                \n",
    "target_3d_mask_predict = target_3d_mask_predict1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "affine = np.diag([1, 2, 3,1])\n",
    "img_3d = nib.Nifti1Image(target_3d_mask_predict, affine)\n",
    "img_3d.shape\n",
    "nib.save(img_3d, file_path+file_number+file_number+'_mask1.nii')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def m_filter1(ifile,x,y,z,step=3):\n",
    "    sum_s=[]\n",
    "    for i in range(-int(step/2),int(step/2)+1):\n",
    "        for j in  range(-int(step/2),int(step/2)+1):\n",
    "            for k in  range(-int(step/2),int(step/2)+1):\n",
    "                sum_s.append(ifile[x+i][y+j][z+k])\n",
    "    sum_s.sort()\n",
    "    #print(sum_s)\n",
    "    return sum_s[int(step*step*step/2)+12]\n",
    "\n",
    "a,b,c = target_3d_mask_predict.shape\n",
    "target_3d_mask_predict3 = np.zeros((a,b,c))\n",
    "\n",
    "for x in range(1,a-1):\n",
    "    print(x)\n",
    "    for y in range(1,b-1):\n",
    "        for z in range(1,c-1):\n",
    "            if target_3d_mask_predict[x,y,z] == 255:\n",
    "                target_3d_mask_predict3[x,y,z] = m_filter1(target_3d_mask_predict,x,y,z)\n",
    "\n",
    "# affine = np.diag([1, 2, 3,1])\n",
    "# img_3d = nib.Nifti1Image(target_3d_mask_predict3, affine)\n",
    "# img_3d.shape\n",
    "# nib.save(img_3d, file_path+file_number+file_number+'_mask1_3.nii')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b,c = target_3d_mask_predict.shape\n",
    "target_mask2 = np.zeros((a,b,c))\n",
    "for x in range(a):\n",
    "    for y in range(b):\n",
    "        for z in range(c):\n",
    "            if (0<x<10 or a-10<x<a) or z<5:\n",
    "                target_mask2[x,y,z] = 0\n",
    "            else:\n",
    "                target_mask2[x,y,z] = target_3d_mask_predict3[x,y,z]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def small_vessel_search2(ifile,ifile2,gradient_rate,step_rate,at_least,xs=0,ys=0,zs=150):\n",
    "    a,b,c = target_3d_mask_predict.shape\n",
    "    points = []\n",
    "    patch_len = 9\n",
    "\n",
    "    for x in range(4+10,a-4-xs):\n",
    "        for y in range(4+ys,b-40-4):\n",
    "            for z in range(4+zs,c-20-4):\n",
    "                if ifile[x,y,z] == 255:\n",
    "                    for _i,_j,_k in d3_plat_1_no0:\n",
    "                        x1,y1,z1 = x+_i*step_rate,y+_j*step_rate,z+_k*step_rate\n",
    "                        if ifile[x1,y1,z1]==0 and ifile2[x1,y1,z1]>at_least:\n",
    "                            points.append([x1,y1,z1])\n",
    "\n",
    "    return points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in range(1):\n",
    "    print(n)\n",
    "    gradient_points = small_vessel_search2(target_mask2,target_same_insert,1.3,1,125,xs=10,ys=20,zs=10)\n",
    "    for x,y,z in gradient_points:\n",
    "        #print([x,y,z])\n",
    "        target_mask2[x,y,z] = 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# affine = np.diag([1, 2, 3,1]) \n",
    "# img_3d = nib.Nifti1Image(target_mask2, affine) \n",
    "# img_3d.shape \n",
    "# nib.save(img_3d, file_path+file_number+file_number+'_mask2.nii')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def m_filter2(ifile,x,y,z,step=3):\n",
    "    sum_s=[]\n",
    "    for i in range(-int(step/2),int(step/2)+1):\n",
    "        for j in  range(-int(step/2),int(step/2)+1):\n",
    "            for k in  range(-int(step/2),int(step/2)+1):\n",
    "                sum_s.append(ifile[x+i][y+j][z+k])\n",
    "    sum_s.sort()\n",
    "    #print(sum_s)\n",
    "    return sum_s[int(step*step*step/2)+9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a,b,c = target_3d_mask_predict.shape\n",
    "target_mask4 = np.zeros((a,b,c))\n",
    "\n",
    "for x in range(1,a-1):\n",
    "    print(x)\n",
    "    for y in range(1,b-1):\n",
    "        for z in range(1,c-1):\n",
    "            if target_mask2[x,y,z] == 255:\n",
    "                if z<200:\n",
    "                    target_mask4[x,y,z] = m_filter2(target_mask2,x,y,z)\n",
    "                else:\n",
    "                    target_mask4[x,y,z] = target_mask2[x,y,z]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# affine = np.diag([1, 2, 3,1]) \n",
    "# img_3d = nib.Nifti1Image(target_mask4, affine) \n",
    "# img_3d.shape \n",
    "# nib.save(img_3d, file_path+file_number+file_number+'_mask4.nii')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def m_filter3(ifile,x,y,z,step=3):\n",
    "    sum_s=[]\n",
    "    for i in range(-int(step/2),int(step/2)+1):\n",
    "        for j in  range(-int(step/2),int(step/2)+1):\n",
    "            for k in  range(-int(step/2),int(step/2)+1):\n",
    "                sum_s.append(ifile[x+i][y+j][z+k])\n",
    "    sum_s.sort()\n",
    "    #print(sum_s)\n",
    "    return sum_s[int(step*step*step/2)+5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a,b,c = target_3d_mask_predict.shape\n",
    "target_mask5 = np.zeros((a,b,c))\n",
    "\n",
    "for x in range(1,a-1):\n",
    "    print(x)\n",
    "    for y in range(1,b-1):\n",
    "        for z in range(1,c-1):\n",
    "            if target_mask4[x,y,z] == 0:\n",
    "                target_mask5[x,y,z] = m_filter3(target_mask4,x,y,z)\n",
    "            else:\n",
    "                target_mask5[x,y,z] = 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "affine = np.diag([1, 2, 3,1]) \n",
    "img_3d = nib.Nifti1Image(target_mask5, affine) \n",
    "img_3d.shape \n",
    "nib.save(img_3d, file_path+file_number+file_number+'_mask5.nii')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_groups(origin,g_number,n_number):\n",
    "    groups = []\n",
    "    now_points = []\n",
    "    repeats = []\n",
    "    g = 0\n",
    "    number = -1\n",
    "    for x,y,z in origin:\n",
    "        number = number+1\n",
    "        if number%1000 == 0:\n",
    "            print(number)\n",
    "        #if g >= 1:\n",
    "            #break\n",
    "        \n",
    "        #length_group = len(repeats)#开始迭代时分组个数\n",
    "        #print([x,y,z])\n",
    "        if [x,y,z] not in repeats:#确定不在其他小组中\n",
    "            if [x,y,z] not in now_points:#确定不会重复统计本小组中的点\n",
    "                already_points = []\n",
    "\n",
    "                if len(now_points) == 0:#如果是小组中第一个点，就干脆把周围一圈的点都计算进来\n",
    "                    now_points.append([x,y,z])\n",
    "                    for i,j,k in d3_plat_1_no0:\n",
    "                        if [x+i,y+j,z+k] in origin:\n",
    "                            now_points.append([x+i,y+j,z+k])\n",
    "                            already_points.append([x+i,y+j,z+k])\n",
    "                \n",
    "                for iteration in range(n_number):\n",
    "                    length = len(now_points)#开始迭代时当前小组坐标点个数\n",
    "                    #print(iteration)\n",
    "                    temporary_points = []\n",
    "\n",
    "                    for i,j,k in d3_plat_1_no0:#如果不是小组中第一个点，就判断周围是不是有这个小组的点，如果有就加入进来\n",
    "                        for x1,y1,z1 in already_points:\n",
    "                            if [x1+i,y1+j,z1+k] in origin:\n",
    "                                if [x1+i,y1+j,z1+k] not in now_points:\n",
    "                                    now_points.append([x1+i,y1+j,z1+k])\n",
    "                                    temporary_points.append([x1+i,y1+j,z1+k])\n",
    "\n",
    "                    already_points = []\n",
    "                    for x,y,z in temporary_points:\n",
    "                        already_points.append([x,y,z])\n",
    "\n",
    "                    if len(now_points) == length:#如果坐标点个数没有增加就结束迭代 \n",
    "                        #print(length)\n",
    "                        groups.append(now_points)#将不再增加的这一小组坐标点作为一个小组加入到分组中\n",
    "                        for xxx,yyy,zzz in groups[g]:#将这一小组列入已经计算的小组，防止重复计算\n",
    "                            repeats.append([xxx,yyy,zzz])\n",
    "                        \n",
    "                        now_points = []#这一小组坐标点归零，准备开始新的一个小组\n",
    "                        g = g+1\n",
    "                        #print(g)\n",
    "                        break\n",
    "            \n",
    "    return groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b,c = target_mask5.shape\n",
    "for x in range(a):\n",
    "    for y in range(b):\n",
    "        for z in range(c):\n",
    "            if x<10 or x>a-10:\n",
    "                target_mask5[x,y,z] = 0\n",
    "            if z<10:\n",
    "                target_mask5[x,y,z] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "affine = np.diag([1, 2, 3,1]) \n",
    "img_3d = nib.Nifti1Image(target_mask5, affine) \n",
    "img_3d.shape \n",
    "nib.save(img_3d, file_path+file_number+file_number+'_mask5.nii')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rate_in_patch(point,ifile,patch0=11,patch1=11,patch2=11):\n",
    "    x,y,z = point\n",
    "    patch = ifile[x-int((patch0-1)/2):x+int((patch0-1)/2+1),y-int((patch1-1)/2):y+int((patch1-1)/2+1),z-int((patch2-1)/2):z+int((patch2-1)/2+1)]\n",
    "    #print(patch.shape)\n",
    "    #print(ifile[x,y,z])\n",
    "    brights = []\n",
    "    for i in range(patch0):\n",
    "        for j in range(patch1):\n",
    "            for k in range(patch2):\n",
    "                brights.append(patch[i,j,k])\n",
    "    #print(brights)\n",
    "    \n",
    "    rate = ifile[x,y,z]/max(brights)\n",
    "    return rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rate_in_patch2(point,ifile,ifile2,patch0=11,patch1=11,patch2=11):\n",
    "    x,y,z = point\n",
    "    patch = ifile[x-int((patch0-1)/2):x+int((patch0-1)/2+1),y-int((patch1-1)/2):y+int((patch1-1)/2+1),z-int((patch2-1)/2):z+int((patch2-1)/2+1)]\n",
    "    patch_i = ifile2[x-int((patch0-1)/2):x+int((patch0-1)/2+1),y-int((patch1-1)/2):y+int((patch1-1)/2+1),z-int((patch2-1)/2):z+int((patch2-1)/2+1)]\n",
    "    #print(patch_i.shape)\n",
    "    #print(ifile[x,y,z])\n",
    "    brights = []\n",
    "    points = []\n",
    "    for i in range(patch0):\n",
    "        for j in range(patch1):\n",
    "            for k in range(patch2):\n",
    "                #print(i,j,k)\n",
    "                brights.append(patch[i,j,k])\n",
    "                if patch_i[i,j,k] == 255:\n",
    "                    points.append([i,j,k])\n",
    "    #print(brights)\n",
    "    \n",
    "    intensity_rate = ifile[x,y,z]/max(brights)\n",
    "    #print(ifile[x,y,z],max(brights))\n",
    "    density = len(points)/(patch0*patch1*patch2)\n",
    "    return intensity_rate,density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b,c = target_mask5.shape\n",
    "target_mask6 = np.zeros((a,b,c))\n",
    "for x in range(a):\n",
    "    for y in range(b):\n",
    "        for z in range(c):\n",
    "            target_mask6[x,y,z] = target_3d_insert2[x,y,z]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    img = target_mask6\n",
    "    img_shape = (img.shape[0], img.shape[1], img.shape[2])\n",
    "    t0,t1,t2 = int(img.shape[0]/3), int(img.shape[1]/3), int(img.shape[2]/3)\n",
    "    dst_shape = (t0,t1,t2)\n",
    "    target_mask6_re = bilinear(img, img_shape, dst_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b,c = target_mask6_re.shape\n",
    "for x in range(a):\n",
    "    for y in range(b):\n",
    "        for z in range(c):\n",
    "            if target_mask6_re[x,y,z]>125:\n",
    "                target_mask6_re[x,y,z] = 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b,c = target_mask6_re.shape\n",
    "#target_3d_4 = np.zeros((a,b,c))\n",
    "\n",
    "sembles = []\n",
    "for x in range(a):\n",
    "    for y in range(b):\n",
    "        for z in range(c):\n",
    "            if target_mask6_re[x,y,z] == 255:\n",
    "                sembles.append([x,y,z])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "groups = make_groups(sembles,10000,1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups2 = groups.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for n in range(len(groups2)):\n",
    "    if len(groups2[n])>100:\n",
    "        print(len(groups2[n]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b,c = target_mask6.shape\n",
    "#target_3d_4 = np.zeros((a,b,c))\n",
    "\n",
    "sembles2 = []\n",
    "for x in range(a):\n",
    "    for y in range(b):\n",
    "        for z in range(c):\n",
    "            if target_mask6[x,y,z] == 255:\n",
    "                sembles2.append([x,y,z])\n",
    "len(sembles2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lenths = []\n",
    "for n in range(len(groups2)):\n",
    "    lenths.append(len(groups2[n]))\n",
    "lenths_big = max(lenths)\n",
    "print(lenths_big)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def small_group_to_big(small_group,ifile,semble):\n",
    "    a,b,c = ifile.shape\n",
    "    big_group = []\n",
    "    repeats = []\n",
    "    for n in range(len(small_group)):\n",
    "        if n%100 == 0:\n",
    "            print(n/100)\n",
    "        big_group.append([])\n",
    "#         if len(small_group[n])>lenths_big-1000:\n",
    "#             big_number = n\n",
    "#             pass\n",
    "#         else:\n",
    "        print('len of group',len(small_group[n]))\n",
    "        for m in range(len(small_group[n])):\n",
    "            if m%1000 == 0:\n",
    "                print(m/1000)\n",
    "            x,y,z = small_group[n][m]\n",
    "            x1,y1,z1 = int(x*3+1),int(y*3+1),int(z*3+1)\n",
    "            if x1<a-1 and y1<b-1 and z1<c-1:\n",
    "                for i,j,k in d3_plat_1:\n",
    "                    if ifile[x1+i,y1+j,z1+k] == 255:# and [x1+i,y1+j,z1+k] not in big_group[n]:\n",
    "                        big_group[n].append([x1+i,y1+j,z1+k])\n",
    "                        repeats.append([x1+i,y1+j,z1+k])\n",
    "            x2,y2,z2 = int(x*3),int(y*3),int(z*3)\n",
    "            if x1<a-1 and y1<b-1 and z1<c-1:\n",
    "                for i,j,k in d3_plat_1:\n",
    "                    if ifile[x2+i,y2+j,z2+k] == 255:# and [x2+i,y2+j,z2+k] not in big_group[n]： and [x2+i,y2+j,z2+k] not in repeats:\n",
    "                        big_group[n].append([x2+i,y2+j,z2+k])\n",
    "                        repeats.append([x2+i,y2+j,z2+k])\n",
    "                            \n",
    "#     semble_copy = semble\n",
    "#     #number = 0\n",
    "#     #print(1)\n",
    "#     for n1 in range(len(repeats)):\n",
    "#         if n1%10000 == 0:\n",
    "#             print(n1/10000)\n",
    "#         if repeats[n1] in semble_copy:\n",
    "#             semble_copy.remove(repeats[n1])\n",
    "#             #number = number+1\n",
    "#     big_group[big_number] = semble_copy\n",
    "    return big_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "groups2_insert = small_group_to_big(groups2,target_mask6,sembles2)\n",
    "end = time.time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_3d_hessian_matrix(nd_array, sigma=1, scale=True, whiteonblack=True):\n",
    "    \"\"\"\n",
    "    Computes the hessian matrix for an nd_array.\n",
    "    This can be used to detect vesselness as well as other features.\n",
    "    In 3D the first derivative will contain three directional gradients at each index:\n",
    "    [ gx,  gy,  gz ]\n",
    "    The Hessian matrix at each index will then be equal to the second derivative:\n",
    "    [ gxx, gxy, gxz]\n",
    "    [ gyx, gyy, gyz]\n",
    "    [ gzx, gzy, gzz]\n",
    "    The Hessian matrix is symmetrical, so gyx == gxy, gzx == gxz, and gyz == gzy.\n",
    "    :param nd_array: n-dimensional array from which to compute the hessian matrix.\n",
    "    :param sigma: gaussian smoothing to perform on the array.\n",
    "    :param scale: if True, the hessian elements will be scaled by sigma squared.\n",
    "    :return: hessian array of shape (..., ndim, ndim)\n",
    "    \"\"\"\n",
    "    ndim = nd_array.ndim\n",
    "\n",
    "    # smooth the nd_array\n",
    "    smoothed = ndi.gaussian_filter(nd_array, sigma=sigma, mode='nearest', truncate=3.0)\n",
    "\n",
    "    # compute the first order gradients\n",
    "    gradient_list = np.gradient(smoothed)\n",
    "\n",
    "    # compute the hessian elements\n",
    "    hessian_elements = [np.gradient(gradient_list[ax0], axis=ax1)\n",
    "                        for ax0, ax1 in combinations_with_replacement(range(ndim), 2)]\n",
    "\n",
    "    if sigma > 0 and scale:\n",
    "        # scale the elements of the hessian matrix\n",
    "        if whiteonblack:\n",
    "            hessian_elements = [(sigma ** 2) * element for element in hessian_elements]\n",
    "        else:\n",
    "            hessian_elements = [-1 * (sigma ** 2) * element for element in hessian_elements]\n",
    "\n",
    "    # create hessian matrix from hessian elements\n",
    "    hessian_full=[[()] * ndim for x in range(ndim)]\n",
    "    #hessian_full = [[None] * ndim] * ndim\n",
    "\n",
    "    for index, (ax0, ax1) in enumerate(combinations_with_replacement(range(ndim), 2)):\n",
    "        element = hessian_elements[index]\n",
    "        hessian_full[ax0][ax1] = element\n",
    "        if ax0 != ax1:\n",
    "            hessian_full[ax1][ax0] = element\n",
    "\n",
    "    hessian_rows = list()\n",
    "    for row in hessian_full:\n",
    "        #print(row.shape)\n",
    "        hessian_rows.append(np.stack(row, axis=-1))\n",
    "\n",
    "    hessian = np.stack(hessian_rows, axis=-2)\n",
    "    return hessian\n",
    "\n",
    "\n",
    "def absolute_3d_hessian_eigenvalues(nd_array, sigma=1, scale=True, whiteonblack=True):\n",
    "    \"\"\"\n",
    "    Eigenvalues of the hessian matrix calculated from the input array sorted by absolute value.\n",
    "    :param nd_array: input array from which to calculate hessian eigenvalues.\n",
    "    :param sigma: gaussian smoothing parameter.\n",
    "    :param scale: if True hessian values will be scaled according to sigma squared.\n",
    "    :return: list of eigenvalues [eigenvalue1, eigenvalue2, ...]\n",
    "    \"\"\"\n",
    "    return np.absolute(compute_3d_hessian_matrix(nd_array, sigma=sigma, scale=scale, whiteonblack=whiteonblack))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_center_point(semble):\n",
    "    xc,yc,zc = 0,0,0\n",
    "    for n in range(len(semble)):\n",
    "        x,y,z = semble[n]\n",
    "        xc = xc+x\n",
    "        yc = yc+y\n",
    "        zc = zc+z\n",
    "    xc = int(xc/len(semble))\n",
    "    yc = int(yc/len(semble))\n",
    "    zc = int(zc/len(semble))\n",
    "    center_point = [xc,yc,zc]\n",
    "    return center_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in range(len(groups2_insert)):\n",
    "    print(len(groups2_insert[n]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(groups2_insert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "patch_len = 11\n",
    "step = 5\n",
    "a,b,c = target_mask5.shape\n",
    "target_mask6_1 = np.zeros((a,b,c))\n",
    "for n in range(len(groups2_insert)):\n",
    "    print(n)\n",
    "#     if len(groups2[n])>1000:\n",
    "#         print(len(groups2[n]))\n",
    "    if len(groups2_insert[n])>=500000:# and len(groups2[n])!=1054:\n",
    "        for m in range(len(groups2_insert[n])):\n",
    "            x,y,z = groups2_insert[n][m]\n",
    "            #if target_mask5[x,y,z] > 50:\n",
    "            target_mask6_1[x,y,z] = 255\n",
    "#     elif 100000<len(groups2_insert[n])<300000:\n",
    "#         pass\n",
    "    else:\n",
    "        for m in range(len(groups2_insert[n])):\n",
    "            x,y,z = groups2_insert[n][m]\n",
    "#             if target_same[x,y,z] > 80:\n",
    "#                 target_mask6[x,y,z] = 255\n",
    "            if 10<x<a-10 and 10<y<b-10 and 10<z<c-10:\n",
    "                points_brights = []\n",
    "                for i in range(patch_len):\n",
    "                    for j in range(patch_len):\n",
    "                        for k in range(patch_len):\n",
    "                            points_brights.append(target_same_insert[int(x+i-((patch_len-1)/2)),int(y+j-((patch_len-1)/2)),int(z+k-((patch_len-1)/2))])\n",
    "                aver_bright = sum(points_brights)/len(points_brights)\n",
    "                if target_same_insert[x,y,z]/aver_bright>1.3 and target_same_insert[x,y,z]>intsl and z>50 and len(groups2_insert[n])>50:\n",
    "                    target_mask6_1[x,y,z] = 255\n",
    "                elif z>c/6 and target_same_insert[x,y,z]>intsh+20:\n",
    "                    target_mask6_1[x,y,z] = 255\n",
    "                    \n",
    "for x in range(a):\n",
    "    for y in range(b):\n",
    "        for z in range(c):\n",
    "            target_mask6_1[x,y,z] = target_mask6[x,y,z]\n",
    "                    \n",
    "end = time.time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# affine = np.diag([1, 2, 3,1])\n",
    "# img_3d = nib.Nifti1Image(target_mask6_1, affine)\n",
    "# #img_3d.shape\n",
    "# nib.save(img_3d, file_path+file_number+file_number+'_mask6-2.nii')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x,y,z = 671,376,115\n",
    "for n in range(len(groups2_insert)):\n",
    "    if [x,y,z] in groups2_insert[n]:\n",
    "        break\n",
    "if 10000<len(groups2_insert[n])<80000:\n",
    "    xc,yc,zc = find_center_point(groups2_insert[n])\n",
    "    if step<xc<a-step and step<yc<b-step and step<zc<c-step:\n",
    "        array = target_mask6_1[xc-step:xc+step,yc-step:yc+step,zc-step:zc+step]\n",
    "        result = compute_3d_hessian_matrix(array, sigma=cita, scale=True, whiteonblack=True)\n",
    "        A = np.mat(result[step][step][step])\n",
    "        U = A*A.T\n",
    "        lamda,hU=np.linalg.eig(U)\n",
    "        sigma=np.sqrt(lamda)\n",
    "        result2 = [sigma[0],sigma[1],sigma[2]]\n",
    "        if min(result2)==0 and max(result2)!=0:\n",
    "            dc = max(result2)/0.000001\n",
    "        elif min(result2)==0 and max(result2)==0:\n",
    "            dc = 100\n",
    "        else:\n",
    "            dc = max(result2)/min(result2)\n",
    "    else:\n",
    "        dc = -10\n",
    "print(dc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_mask8_1 = np.zeros((a,b,c))\n",
    "step = 5\n",
    "cita=1.5\n",
    "for n in range(len(groups2_insert)):\n",
    "    if 10000<len(groups2_insert[n])<100000:\n",
    "        xc,yc,zc = find_center_point(groups2_insert[n])\n",
    "        if step<xc<a-step and step<yc<b-step and step<zc<c-step:\n",
    "            array = target_mask6_1[xc-step:xc+step,yc-step:yc+step,zc-step:zc+step]\n",
    "            result = compute_3d_hessian_matrix(array, sigma=cita, scale=True, whiteonblack=True)\n",
    "            A = np.mat(result[step][step][step])\n",
    "            U = A*A.T\n",
    "            lamda,hU=np.linalg.eig(U)\n",
    "            sigma=np.sqrt(lamda)\n",
    "            result2 = [sigma[0],sigma[1],sigma[2]]\n",
    "            if min(result2)==0 and max(result2)!=0:\n",
    "                dc = max(result2)/0.000001\n",
    "            elif min(result2)==0 and max(result2)==0:\n",
    "                dc = 100\n",
    "            else:\n",
    "                dc = max(result2)/min(result2)\n",
    "        else:\n",
    "            dc = -10\n",
    "        if dc>10:\n",
    "            for m in range(len(groups2_insert[n])):\n",
    "                x,y,z = groups2_insert[n][m]\n",
    "                target_mask8_1[x,y,z] = 255\n",
    "    else:\n",
    "        for m in range(len(groups2_insert[n])):\n",
    "            x,y,z = groups2_insert[n][m]\n",
    "            if target_mask6_1[x,y,z] == 255:\n",
    "                target_mask8_1[x,y,z] = 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "affine = np.diag([1, 2, 3,1])\n",
    "img_3d = nib.Nifti1Image(target_mask8_1, affine)\n",
    "#img_3d.shape\n",
    "nib.save(img_3d, file_path+file_number+file_number+'_mask8-1.nii')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_filter(ifile,x,y,z,step=3):\n",
    "    sum_s=[]\n",
    "    for i in range(-int(step/2),int(step/2)+1):\n",
    "        for j in  range(-int(step/2),int(step/2)+1):\n",
    "            for k in  range(-int(step/2),int(step/2)+1):\n",
    "                sum_s.append(ifile[x+i][y+j][z+k])\n",
    "    sum_s.sort()\n",
    "    #print(sum_s)\n",
    "    return sum_s[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_filter(ifile,x,y,z,step=3):\n",
    "    sum_s=[]\n",
    "    for i in range(-int(step/2),int(step/2)+1):\n",
    "        for j in  range(-int(step/2),int(step/2)+1):\n",
    "            for k in  range(-int(step/2),int(step/2)+1):\n",
    "                #print([x+i,y+j,z+k])\n",
    "                sum_s.append(ifile[x+i][y+j][z+k])\n",
    "    sum_s.sort()\n",
    "    #print(sum_s)\n",
    "    return sum_s[len(sum_s)-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a,b,c = target_3d_insert2.shape\n",
    "\n",
    "centerline_semble = []\n",
    "target_temp = target_3d_insert2\n",
    "\n",
    "step1 = 4\n",
    "for step2 in range(3):\n",
    "    target_min = np.zeros((a,b,c))\n",
    "    target_max = np.zeros((a,b,c))\n",
    "    vessel_mask = []\n",
    "    print(step2)\n",
    "    pad = int((step1-1)/2+2)\n",
    "    for x in range(pad,a-pad):\n",
    "        for y in range(pad,b-pad):\n",
    "            for z in range(pad,c-pad):\n",
    "                if target_temp[x,y,z] == 255:\n",
    "                    target_min[x,y,z] = min_filter(target_temp,x,y,z,step=step1)\n",
    "                    #if step2==0:\n",
    "                    vessel_mask.append([x,y,z])\n",
    "\n",
    "    for n in range(len(vessel_mask)):\n",
    "        x,y,z = vessel_mask[n]\n",
    "        if target_min[x,y,z] == 0:\n",
    "            if step2==0:\n",
    "                target_max[x,y,z] = max_filter(target_min,x,y,z,step=step1)\n",
    "            else:\n",
    "                target_max[x,y,z] = max_filter(target_min,x,y,z,step=step1+2)\n",
    "        else:\n",
    "            target_max[x,y,z] = 255\n",
    "\n",
    "    for n in range(len(vessel_mask)):\n",
    "        x,y,z = vessel_mask[n]\n",
    "        if target_temp[x,y,z] == 255 and target_max[x,y,z] == 0 and step2>=1:\n",
    "             centerline_semble.append([x,y,z])\n",
    "    target_temp = target_min\n",
    "target_c = np.zeros((a,b,c))\n",
    "for n in range(len(centerline_semble)):\n",
    "    x,y,z = centerline_semble[n]\n",
    "    target_c[x,y,z] = 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "affine = np.diag([1, 2, 3,1])\n",
    "img_3d = nib.Nifti1Image(target_c, affine)\n",
    "#img_3d.shape\n",
    "nib.save(img_3d, file_path+file_number+file_number+'_maskc.nii')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_3d_insert3 = target_mask8_1\n",
    "a,b,c = target_3d_insert3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_center_3d(group):\n",
    "    xc,yc,zc = 0,0,0\n",
    "    for n in range(len(group)):\n",
    "        x,y,z = group[n]\n",
    "        xc += x\n",
    "        yc += y\n",
    "        zc += z\n",
    "    xc,yc,zc = int(xc/len(group)),int(yc/len(group)),int(zc/len(group))\n",
    "    return xc,yc,zc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clusters_init(ifile,groups,point_number_down=200,point_number_up=100000):\n",
    "    init_centers = []\n",
    "    a,b,c = ifile.shape\n",
    "    for n in range(len(groups)):\n",
    "        if point_number_down<len(groups[n])<point_number_up:#找到目标cluster\n",
    "            \n",
    "            z_semble = []\n",
    "            point_semble = []\n",
    "            min_z_point_semble = []\n",
    "            for m in range(len(groups[n])):\n",
    "                z_semble.append(groups[n][m][2])\n",
    "                point_semble.append(groups[n][m])\n",
    "            if min(z_semble)>c*0.8:\n",
    "                pass\n",
    "            else:\n",
    "                z_semble = np.array(z_semble)\n",
    "                #print(z_semble)\n",
    "                min_z = np.where(z_semble==min(z_semble))\n",
    "                #print(min_z)\n",
    "            \n",
    "                for min_z_list in list(min_z):\n",
    "                    for index in min_z_list:\n",
    "                        min_z_point_semble.append(point_semble[index])\n",
    "                init_center = get_center_3d(min_z_point_semble)\n",
    "                init_centers.append(list(init_center))\n",
    "                \n",
    "    return init_centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "centers = get_clusters_init(target_3d_insert3,groups2_insert)\n",
    "print(len(centers),centers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tesdic = {\n",
    "        'cluster': centers,\n",
    "        }\n",
    "with open(file_path+file_number+file_number+'_cluster.json', 'w', encoding='utf-8') as fw:\n",
    "      json.dump(tesdic, fw, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
